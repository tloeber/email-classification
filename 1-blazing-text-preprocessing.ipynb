{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08a42f34-335e-4389-b353-4930877e34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable current type hints for older Python version (<3.10) \n",
    "from __future__ import annotations\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9044951-cdde-4021-bf2d-41935edf1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge  -y python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2577a8a2-b67f-4144-9692-c12532d024f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "BUCKET = config['BUCKET']\n",
    "PREPROCESSING_INPUT_KEY = config['PREPROCESSING_INPUT_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a675322c-1232-45a0-90dd-299c278cea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local directories needed, if they don't exist yet\n",
    "try:\n",
    "    Path('data').mkdir(exist_ok=False)\n",
    "except FileExistsError:\n",
    "    logger.info('Directory already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9956edb-33fe-412b-909a-aa6b011a05d2",
   "metadata": {},
   "source": [
    "# Read data\n",
    "See the \"data-pipeline\" directory for how to get and persist the data as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cddf7422-f025-41d6-ba58-1f0bf1120462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replied_to</th>\n",
       "      <th>sender</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183cb6c70075704b</th>\n",
       "      <td>False</td>\n",
       "      <td>Anthem-healthspendingaccounts@mail2.anthem.com</td>\n",
       "      <td>[http://images.myhealthyfinances.com/EloquaIma...</td>\n",
       "      <td>1665565214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183ca91acbdcd4f8</th>\n",
       "      <td>False</td>\n",
       "      <td>FloTechnologies &lt;no-reply@meetflo.com&gt;</td>\n",
       "      <td>\\n\\n\\n\\n\\nWarning:\\r\\n    Low Battery\\r\\n    \\...</td>\n",
       "      <td>1665550886000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  replied_to                                          sender  \\\n",
       "183cb6c70075704b       False  Anthem-healthspendingaccounts@mail2.anthem.com   \n",
       "183ca91acbdcd4f8       False          FloTechnologies <no-reply@meetflo.com>   \n",
       "\n",
       "                                                               body  \\\n",
       "183cb6c70075704b  [http://images.myhealthyfinances.com/EloquaIma...   \n",
       "183ca91acbdcd4f8  \\n\\n\\n\\n\\nWarning:\\r\\n    Low Battery\\r\\n    \\...   \n",
       "\n",
       "                      timestamp  \n",
       "183cb6c70075704b  1665565214000  \n",
       "183ca91acbdcd4f8  1665550886000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "PREPROCESSING_INPUT_PATH = 'data/preprocessing_input.parquet'\n",
    "\n",
    "s3.download_file(\n",
    "    Bucket=BUCKET, \n",
    "    Key=PREPROCESSING_INPUT_KEY,\n",
    "    Filename=PREPROCESSING_INPUT_PATH,\n",
    ")\n",
    "\n",
    "df = pq.read_table(PREPROCESSING_INPUT_PATH)\n",
    "df = df.to_pandas()\n",
    "df.iloc[1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1af94cdf-f46c-4a0c-8e89-04df60c2db78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26695"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af88119-8cae-4eb3-8a3e-8e2efede8e5f",
   "metadata": {},
   "source": [
    "# Clean and transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36850208-322f-4b24-8619-e20d236942d2",
   "metadata": {},
   "source": [
    "## Drop rows\n",
    "ToDo: Do this as part of the data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0999a39-d4d8-4bd8-acd7-1f03f2fadf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    388\n",
       "Name: replied_to, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop emails frowarded from my other inbox\n",
    "df.loc[\n",
    "    df.sender.str.contains('loeberthomas@yahoo.com'), \n",
    "    'replied_to'\n",
    "] \\\n",
    ".value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2434d9c1-d7aa-441c-bf5b-e5f50b834101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[\n",
    "    ~df.sender.str.contains('loeberthomas@yahoo.com'),\n",
    "    :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aea2859b-98d0-4e51-866f-48fe1ec3f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop emails whith empty body\n",
    "df = df.loc[\n",
    "    df.body.map(len) > 0,\n",
    "    :\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec052a0-1445-4c9b-9642-4614f4b819df",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "In this step, we put the data in the format required by the blazing text algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "503877e0-75b6-4f9d-a8d9-1abd929bdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Deprecated in /opt/conda/lib/python3.8/site-packages (1.2.13)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.8/site-packages (from Deprecated) (1.12.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "318c9667-73fb-4308-8afc-d665db8c76ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    24234\n",
       "1      261\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from deprecated import deprecated\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "@deprecated(reason='Use jsonlines format, which requires `label` column.')\n",
    "def create_target(s):\n",
    "    \"\"\"Target as required by Blazing Text IF USING PLAINTEXT FORMAT.\"\"\"\n",
    "    label = \"reply\" if s == True else \"no_reply\"\n",
    "    return f'__label__{label}'\n",
    "\n",
    "# Convert training data into right format for tensorflow\n",
    "def strip_non_ascii_chars(string_: str) -> str:\n",
    "    return string_.encode('ascii', errors='ignore').decode()\n",
    "\n",
    "def replace_chars_for_csv(string_: str) -> str:\n",
    "    return string_.replace('\\n', ' ') \\\n",
    "        .replace(',', ' ')\n",
    "\n",
    "def tokenize(s):\n",
    "    token_list = nltk.word_tokenize(s)\n",
    "    return ' '.join(token_list)\n",
    "\n",
    "# label as required by Blazing Text IF USING PLAINTEXT FORMAT\n",
    "df['label'] = df.replied_to.astype(int)\n",
    "\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "430d9634-0542-4779-8c18-ceffc16ad96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature'] = df.body.map(strip_non_ascii_chars) \\\n",
    "    .map(replace_chars_for_csv) \\\n",
    "    .map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "124150f0-13b7-4e89-8903-41463c56652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183cbf647a8af438</th>\n",
       "      <td>Good morning families - The technician is here...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183cb6c70075704b</th>\n",
       "      <td>[ http : //images.myhealthyfinances.com/Eloqua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183ca91acbdcd4f8</th>\n",
       "      <td>Warning : Low Battery Warning : Low Battery Vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            feature  label\n",
       "183cbf647a8af438  Good morning families - The technician is here...      0\n",
       "183cb6c70075704b  [ http : //images.myhealthyfinances.com/Eloqua...      0\n",
       "183ca91acbdcd4f8  Warning : Low Battery Warning : Low Battery Vi...      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['feature', 'label']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7e391d7-0ea7-4e85-aaa0-5d175caee322",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.isnull().sum().sum() == 0\n",
    "assert df.feature.str.contains(',').sum() == 0\n",
    "assert df.feature.str.contains('\\n').sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e39ac-f4f0-40be-9520-9cedb78336f0",
   "metadata": {},
   "source": [
    "# Split data\n",
    "Since this data has a time component, we don't randomly split the data. Instead, we make sure to assess the model performance on data that is newer than any data the model has seen during training. This more closely mirrors the situation in production.\n",
    "\n",
    "Note that we have to follow this principle twice: We make sure that the validation data is newer than the training data, and that the test data is newer than the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fcf74c8-e976-4ccc-b50d-d6abcf270be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>18176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "      <td>2426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  label  feature\n",
       "0   test      0     3632\n",
       "1   test      1       43\n",
       "2  train      0    18176\n",
       "3  train      1      195\n",
       "4    val      0     2426\n",
       "5    val      1       23"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify split proportion, then identify corresponding timestamp and split.\n",
    "TRAIN_PROPORTION = 0.75\n",
    "VAL_PROPORTION = 0.1\n",
    "test_proportion = 1 - TRAIN_PROPORTION - VAL_PROPORTION\n",
    "assert test_proportion > 0\n",
    "assert test_proportion < 1\n",
    "\n",
    "train_cutoff = np.quantile(df.timestamp, q=TRAIN_PROPORTION)\n",
    "val_cutoff = np.quantile(df.timestamp, q=TRAIN_PROPORTION+VAL_PROPORTION)\n",
    "\n",
    "def split_dataset(ts):\n",
    "    if ts < train_cutoff:\n",
    "        return 'train'\n",
    "    elif ts > val_cutoff:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'val'\n",
    "    \n",
    "\n",
    "df['split'] = df.timestamp.map(split_dataset)\n",
    "\n",
    "counts = df.groupby(['split', 'label']).feature \\\n",
    "    .count() \\\n",
    "    .reset_index()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "139bb3d2-3f6c-4b4b-a15e-a60677fd7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform actual split\n",
    "df_train = df.loc[df.split == 'train', ['label', 'feature']]\n",
    "df_val = df.loc[df.split == 'val', ['label', 'feature']]\n",
    "df_test = df.loc[df.split == 'test', ['label', 'feature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee97ac6-a28f-4036-9b2d-f2f093dbe629",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Oversample minority class\n",
    "Most emails do not elicit a reply (see barplot below); therefore, maximizing accuracy would probably be misleading. It's easy to get high accuracy simply by predicting that no email will receive a reply.\n",
    "\n",
    "However, since the blazing text algorithm does not allow specifying a different metric to optimize (e.g., F1-score), I simply transform this problem into a balance classification problem by randomly oversampling emails that elicited a reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0514bcd-ed7b-409c-adb2-85831ba57131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = sns.barplot(data=counts, y='split', x='feature', hue='label', orient='h', errwidth=0)\n",
    "p.set_xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9766283-591a-4f2c-8c8c-e903b980353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce587ad2-a7c1-4fb1-994c-ffdc5b4e4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def oversample(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    max_label_count = df.label \\\n",
    "        .value_counts() \\\n",
    "        .max()\n",
    "\n",
    "    ros = RandomOverSampler(\n",
    "        random_state=1, \n",
    "        sampling_strategy={\n",
    "            0: max_label_count,\n",
    "            1: max_label_count,\n",
    "        }    \n",
    "    )\n",
    "    X, y = ros.fit_resample(X=df[['feature']], y=df[['label']])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            'label': y.label,\n",
    "            'feature': X.feature,\n",
    "        }\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_train = oversample(df_train)\n",
    "df_train.label.value_counts()\n",
    "\n",
    "df_val = oversample(df_val)\n",
    "df_val.label.value_counts()\n",
    "\n",
    "# For explainability, use only a subset of test. TODO: oversample replied-tos.\n",
    "df_explain = df_test.sample(\n",
    "    n=20, \n",
    "    random_state=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4765e-b5fe-4d93-84cc-b64d99fed968",
   "metadata": {},
   "source": [
    "We can see that both classes now appear in the same number in both the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f0ce5-5a52-4639-8aa3-9860311c5884",
   "metadata": {},
   "source": [
    "# Write input data\n",
    "Write data in plain text, using pd.to_csv and separating by whitespace. After writing the different data sets, we upload them to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa70acfc-7e44-4381-94ad-ce317aa39740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to train/model-input.jsonl\n",
      "Data uploaded to validation/model-input.jsonl\n",
      "Data uploaded to test/model-input.jsonl\n",
      "Data uploaded to explainability-input/model-input.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Write augmented manifest file/jsonl\n",
    "# ===================================\n",
    "# (For training in pipe mode)\n",
    "\n",
    "# Todo: Use sagemaker experiments & model registry for tracking data versions\n",
    "def write_jsonlines_to_s3(\n",
    "    df: pd.DataFrame, destination_folder: str, add_num_classes: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For test data that will be inputed into batch prediction, set \n",
    "    `add_num_classes` to True. This will add an extra field to each row that \n",
    "    tells prediction to output the probability for all classes (which in turn \n",
    "    makes prediction code more straightforward and reusable.\n",
    "    \"\"\"\n",
    "    logger.debug(\n",
    "        f'Breakdown for {destination_folder}:\\n{df.label.value_counts()}'\n",
    "    )\n",
    "    \n",
    "    if add_num_classes:\n",
    "        num_classes: int = df.label.nunique()\n",
    "        df = df.assign(k=num_classes)\n",
    "    \n",
    "    # Todo: Start using `source` instead of `label` further upstream\n",
    "    df_jsonl = df.rename(columns={'feature': 'source'}) \\\n",
    "        .to_json(orient='records', lines=True)\n",
    "\n",
    "    local_path = Path('data/model-input.jsonl')    \n",
    "    with local_path.open('w') as f:\n",
    "        f.write(df_jsonl)\n",
    "                \n",
    "    s3.upload_file(\n",
    "        Filename=str(local_path),\n",
    "        Bucket=BUCKET,\n",
    "        Key=f'{destination_folder}/model-input.jsonl'\n",
    "    )\n",
    "    \n",
    "    print(f'Data uploaded to {destination_folder}/model-input.jsonl')\n",
    "    \n",
    "    \n",
    "write_jsonlines_to_s3(\n",
    "    df_train[['feature', 'label']], \n",
    "    destination_folder='train'\n",
    ")\n",
    "write_jsonlines_to_s3(\n",
    "    df_val[['feature', 'label']], \n",
    "    destination_folder='validation'\n",
    ")\n",
    "write_jsonlines_to_s3(\n",
    "    df_test[['feature', 'label']], \n",
    "    destination_folder='test',\n",
    "    add_num_classes=True\n",
    ")\n",
    "write_jsonlines_to_s3(\n",
    "    df_explain, \n",
    "    destination_folder='explainability-input'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbde4e95-8dcd-4493-b0ed-b65cfbabe093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/model-input.csv uploaded to plaintext/train.\n",
      "data/model-input.csv uploaded to plaintext/validation.\n",
      "data/model-input.csv uploaded to plaintext/test.\n"
     ]
    }
   ],
   "source": [
    "# Write plain text\n",
    "# ================\n",
    "# (For training in file mode, e.g. for debugging etc)\n",
    "\n",
    "def write_plaintext_to_s3(df: pd.DataFrame, destination_folder: str) -> str:\n",
    "    logger.debug(\n",
    "        f'Breakdown for {destination_folder}:\\n{df.label.value_counts()}'\n",
    "    )\n",
    "    # Format for label differs between pipe and file mode\n",
    "    df['label'] = df.label.map(_create_text_label)\n",
    "           \n",
    "    path_local = 'data/model-input.csv'\n",
    "    \n",
    "    # Using .to_csv() with a whitespace as a separator creates a normal text file\n",
    "    df[['label', 'feature']].to_csv(\n",
    "        path_local,\n",
    "        index=False, \n",
    "        header=False, \n",
    "        sep=' ',\n",
    "    )\n",
    "    \n",
    "    s3.upload_file(\n",
    "        Filename=path_local,\n",
    "        Bucket=BUCKET,\n",
    "        Key=f'{destination_folder}/model-input.csv'\n",
    "    )\n",
    "    print(f'{path_local} uploaded to {destination_folder}.')\n",
    "    \n",
    "\n",
    "def _create_text_label(s):\n",
    "    \"\"\"Convert 0/1 label to text\"\"\"\n",
    "    label = \"reply\" if s else \"no_reply\"\n",
    "    return f'__label__{label}'\n",
    "\n",
    "\n",
    "write_plaintext_to_s3(df_train, destination_folder='plaintext/train')\n",
    "write_plaintext_to_s3(df_val, destination_folder='plaintext/validation')\n",
    "write_plaintext_to_s3(df_test, destination_folder='plaintext/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36b2585b-53c8-43f5-af6d-cedabda06464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist test data for other notebook\n",
    "import pickle\n",
    "with open('df_test.pickle', 'wb') as f:\n",
    "    pickle.dump(obj=df_test, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acb6e2a9-2c63-4fd2-a509-c86d11a42811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at 2022-11-02 11:15:53.237648\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(f'Finished at {datetime.now()}')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:070158674174:studio-lifecycle-config/install-packages-2",
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
